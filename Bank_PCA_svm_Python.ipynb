{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Bank.csv\",sep =\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c= []\n",
    "# for i in range(len(dataset)):\n",
    "#     if dataset[\"y\"][i] == \"unknown\":\n",
    "#         c.append(i)\n",
    "# print(len(c))      \n",
    "    \n",
    "# print(mode(dataset[\"job\"]))\n",
    "a = dataset[\"job\"].replace('unknown','admin',inplace=True)\n",
    "\n",
    "# print(mode(dataset[\"marital\"]))\n",
    "b = dataset[\"marital\"].replace('unknown','married',inplace=True)\n",
    "\n",
    "# print(mode(dataset[\"education\"]))\n",
    "c = dataset[\"education\"].replace('unknown','university.degree',inplace=True)\n",
    "\n",
    "# print(mode(dataset[\"default\"]))\n",
    "d = dataset[\"default\"].replace('unknown','no',inplace=True)\n",
    "\n",
    "# print(mode(dataset[\"housing\"]))\n",
    "e = dataset[\"housing\"].replace('unknown','yes',inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "lb_x = LabelEncoder()\n",
    "x[:,1] = lb_x.fit_transform(x[:, 1])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "\n",
    "\n",
    "lb_x1 = LabelEncoder()\n",
    "x[:,2] = lb_x1.fit_transform(x[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [2])\n",
    "\n",
    "lb_x2 = LabelEncoder()\n",
    "x[:,3] = lb_x2.fit_transform(x[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "\n",
    "lb_x3 = LabelEncoder()\n",
    "x[:,4] = lb_x3.fit_transform(x[:, 4])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [4])\n",
    "\n",
    "lb_x4 = LabelEncoder()\n",
    "x[:,5] = lb_x4.fit_transform(x[:, 5])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [5])\n",
    "\n",
    "lb_x5 = LabelEncoder()\n",
    "x[:,6] = lb_x5.fit_transform(x[:, 6])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [6])\n",
    "\n",
    "lb_x6 = LabelEncoder()\n",
    "x[:,7] = lb_x6.fit_transform(x[:, 7])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [7])\n",
    "\n",
    "lb_x7 = LabelEncoder()\n",
    "x[:,8] = lb_x7.fit_transform(x[:, 8])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [8])\n",
    "\n",
    "lb_x8 = LabelEncoder()\n",
    "x[:,9] = lb_x8.fit_transform(x[:, 9])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [9])\n",
    "\n",
    "lb_x9 = LabelEncoder()\n",
    "x[:,14] = lb_x9.fit_transform(x[:, 14])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [14])\n",
    "\n",
    "lb_y = LabelEncoder()\n",
    "y = lb_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.5,random_state =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components =5)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.fit_transform(x_test)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf',random_state=0)\n",
    "\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18288,     3],\n",
       "       [ 2303,     0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
