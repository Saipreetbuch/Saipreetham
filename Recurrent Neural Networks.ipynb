{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "vocabulary_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words = vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'how', 'br', 'an', 'was', 'did', 'very', 'and', 'to', 'rather', 'his', 'pull', 'in', 'also', 'this', 'likes', 'film', 'past', 'not', 'as', 'image', 'wrong', 'genre', 'it', 'score', 'br', 'that', 'of', 'certainly', 'son', 'it', 'her', 'and', 'along', 'of', 'material', 'of', 'its', 'sad', 'by', 'was', 'your', 'says', 'to', 'movie', 'but', 'of', 'remaining', 'much', 'of', 'mad', 'along', 'son', 'find', 'good', 'br', 'any', 'few', 'his', 'movie', 'do', 'movie', 'from', 'story', 'this', 'is', 'now', 'on', 'when', 'as', 'forest', 'scene', 'interesting', 'even', 'positive', 'is', 'and', 'random', 'using', 'and', 'love', 'to', 'sam', 'period', 'was', 'two', 'was', 'and', 'has', \"didn't\", 'and', 'this', 'of', 'script', 'on', 'having', 'by', 'wayne', 'has', 'unless', 'gets', 'every', 'but', 'is', 'quite', 'br', 'you', 'move', 'action', 'at', 'so', 'and', 'but', 'really', 'yet', 'br', 'night', 'as', \"film's\", 'with', 'way', 'of', 'their', 'horror', 'in', 'at', 'for', 'is', 'got', 'worse', 'me', 'in', 'character', 'be', 'help', 'thin', 'to', 'car', 'be', 'killer', \"can't\", 'received', 'and', 'to', 'movie', 'so', 'respect', 'book', 'and', 'drags', 'is', 'ever', 'br', 'expect', 'and', 'her', 'anything', 'her', 'very', 'not', 'but', 'while', 'secrets', 'past', 'status', 'disney', 'as', 'little', 'it', 'out', 'is', 'top', 'in', 'maybe', '8', 'large', 'j', 'something', 'this', 'is', 'winter', 'really', 'sees', 'one', 'is', 'above', 'question', 'could', 'think', 'actor', 'and', 'released', 'some', 'and', 'he', 'historical', 'are', 'is', 'touching', 'sensitive', 'found', 'this', 'so', 'cheap', 'attempting', 'such', 'to', 'such', 'it', 'for', 'of', 'see', 'my', 'have', 'can', 'give', 'found', 'to', 'and', 'this', 'of', 'script', 'exist', 'on', 'failed', 'title', 'somewhere', 'title', '40', 'even', 'and', 'even', 'seeing', 'and', 'as', '8', 'interest', 'ever', 'but', 'past', 'real', 'movie', 'sometimes', 'movie', 'shown', 'm', 'be', 'jet', \"it's\", 'real', 'character', 'spain', 'and', 'of', 'jerry', 'in', 'can', \"don't\", 'is', 'sets', 'inspector', 'well', 'at', 'unique', 'some', 'this', 'so', 'and', 'too', 'was', 'mr', 'as', 'with', 'man', 'how', 'to', 'performance', 'on', 'bo', 'and', 'to', 'an', 'have', 'interest', 'england', 'some', 'more', 'start', 'his', 'dvd', 'for', 'different', '8', 'to', 'find', 'city', 'even', 'actor', 'they', 'an', 'it', 'and', 'past']\n"
     ]
    }
   ],
   "source": [
    "print([id2word.get(i,' ') for i in x_train[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pad sequences to limit the number of words to same length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "x_train = sequence.pad_sequences(x_train,maxlen=max_words)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16001     \n",
      "=================================================================\n",
      "Total params: 176,001\n",
      "Trainable params: 176,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "embedding_size = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size,embedding_size,input_length = max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation ='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saipr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "24936/24936 [==============================] - 5s 183us/step - loss: 0.4924 - acc: 0.7537 - val_loss: 0.3493 - val_acc: 0.7969\n",
      "Epoch 2/3\n",
      "24936/24936 [==============================] - 4s 172us/step - loss: 0.2431 - acc: 0.9058 - val_loss: 0.2999 - val_acc: 0.9062\n",
      "Epoch 3/3\n",
      "24936/24936 [==============================] - 4s 167us/step - loss: 0.1732 - acc: 0.9378 - val_loss: 0.2842 - val_acc: 0.8281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1794face198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "x_valid,y_valid = x_train[:batch_size],y_train[:batch_size]\n",
    "x_train2,y_train2 = x_train[batch_size:],y_train[batch_size:]\n",
    "model.fit(x_train2,y_train2,validation_data=(x_valid,y_valid),batch_size = batch_size,epochs= num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 74us/step\n",
      "[0.281303983540535, 0.88388]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
